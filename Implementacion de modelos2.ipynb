{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDuhjUENreyA"
   },
   "source": [
    "# Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTKcuRN1S98S"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8ZlGxitq6ju"
   },
   "outputs": [],
   "source": [
    "def error_measures(Yestimado, Yteorico):\n",
    "    \n",
    "    CM = confusion_matrix(Yteorico, Yestimado)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    sens = TP/(TP+FN)\n",
    "    esp = TN/(TN+FP)\n",
    "    \n",
    "    return sens, esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLyQxafGKAzk"
   },
   "outputs": [],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMFagRJ8b2UL"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Opiniones_Hoteles_Medellin.xlsx')\n",
    "df.columns=['texto','sentimiento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xGvxDkqgiKj"
   },
   "outputs": [],
   "source": [
    "X=df.iloc[:,0]\n",
    "y=df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6anhDvLPh9GS"
   },
   "outputs": [],
   "source": [
    "vector=CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32490,
     "status": "ok",
     "timestamp": 1570837474147,
     "user": {
      "displayName": "SANTIAGO QUINTERO HINCAPIE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB3qJOnsWTbakkKoF5HL3bVUM5l1OCBMAvHtcvy=s64",
      "userId": "18242168296718065692"
     },
     "user_tz": 300
    },
    "id": "pd_k0My2h-3v",
    "outputId": "f581ed5a-f653-4141-f7fa-6ca5faeaf821"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5HSw0kJiHuA"
   },
   "outputs": [],
   "source": [
    "bagOfWords=vector.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNdcSSnon9j1"
   },
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKUysH4VoJAJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4S-fBgCWpnKU"
   },
   "outputs": [],
   "source": [
    "def RegresionLogistica(Cvalue):    \n",
    "    kf = KFold(n_splits=10)\n",
    "    lr = LogisticRegression(C = Cvalue, max_iter=200)\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    Errores = np.ones(10)\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    j=0\n",
    "    for train_index, test_index in kf.split(bagOfWords):\n",
    "        Xtrain, Xtest = bagOfWords[train_index], bagOfWords[test_index]\n",
    "        Ytrain, Ytest = y[train_index], y[test_index]  \n",
    "\n",
    "        lr.fit(Xtrain,Ytrain)\n",
    "        Yest = lr.predict(Xtest)\n",
    "        s, e = error_measures(Yest, Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(lr.score(Xtest,Ytest))   \n",
    "        \n",
    "        Errores[j] = classification_error(Yest, Ytest)\n",
    "        j+=1\n",
    "\n",
    "    #print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    #print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    #print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))\n",
    "    return np.mean(acc), np.std(acc), np.mean(sens), np.std(sens), np.mean(esp), np.std(esp), np.mean(Errores), time.time()-tiempo_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32992,
     "status": "error",
     "timestamp": 1570837474754,
     "user": {
      "displayName": "SANTIAGO QUINTERO HINCAPIE",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB3qJOnsWTbakkKoF5HL3bVUM5l1OCBMAvHtcvy=s64",
      "userId": "18242168296718065692"
     },
     "user_tz": 300
    },
    "id": "sM-E-e5uKA0Z",
    "outputId": "78925a76-59e1-4ca2-db00-82b5151b0b1d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanqu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sanqu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\sanqu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0564d997aae453ca574afe4b81cec69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "\n",
    "tasas = pd.Series(['1.0', '0.1','0.001'])\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Tasa de aprendizaje' : tasas})\n",
    "\n",
    "df_types[\"Accuracy\"] = \"\"\n",
    "df_types[\"Int_Accuracy\"] = \"\"\n",
    "df_types[\"Sensibility\"] = \"\"\n",
    "df_types[\"Int_Sensibility\"] = \"\"\n",
    "df_types[\"Especificity\"] = \"\"\n",
    "df_types[\"Int_Especificity\"] = \"\"\n",
    "df_types[\"Error validación\"] = \"\"\n",
    "df_types[\"Tiempo ejecución\"] = \"\"\n",
    "df_types.set_index(['Tasa de aprendizaje'], inplace=True)\n",
    "i=0\n",
    "\n",
    "for eta in [1.0, 0.1, 0.001]:\n",
    "    Acc, IntAcc, Sen, IntSen, Esp, IntEsp, error, tiempo=RegresionLogistica(eta)       \n",
    "    df_types[\"Accuracy\"][i] = Acc\n",
    "    df_types[\"Int_Accuracy\"][i] = IntAcc\n",
    "    df_types[\"Sensibility\"][i] = Sen\n",
    "    df_types[\"Int_Sensibility\"][i] = IntSen\n",
    "    df_types[\"Especificity\"][i] = Esp\n",
    "    df_types[\"Int_Especificity\"][i] = IntEsp\n",
    "    df_types[\"Error validación\"][i] = error\n",
    "    df_types[\"Tiempo ejecución\"][i] = tiempo\n",
    "    i=i+1\n",
    "        \n",
    "\n",
    "# df_types[\"Error_Entrenamiento\"][2] = \"0.0\"\n",
    "# df_types[\"Error_Prueba\"][2] = \"0.5\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VR5PFvGKA0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Int_Accuracy</th>\n",
       "      <th>Sensibility</th>\n",
       "      <th>Int_Sensibility</th>\n",
       "      <th>Especificity</th>\n",
       "      <th>Int_Especificity</th>\n",
       "      <th>Error validación</th>\n",
       "      <th>Tiempo ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tasa de aprendizaje</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.848605</td>\n",
       "      <td>0.0593352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.151395</td>\n",
       "      <td>0.20188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.840799</td>\n",
       "      <td>0.0663257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159201</td>\n",
       "      <td>0.157913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.641516</td>\n",
       "      <td>0.191019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358484</td>\n",
       "      <td>0.10094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy Int_Accuracy Sensibility Int_Sensibility  \\\n",
       "Tasa de aprendizaje                                                      \n",
       "1.0                  0.848605    0.0593352         NaN             NaN   \n",
       "0.1                  0.840799    0.0663257         NaN             NaN   \n",
       "0.001                0.641516     0.191019         NaN             NaN   \n",
       "\n",
       "                    Especificity Int_Especificity Error validación  \\\n",
       "Tasa de aprendizaje                                                  \n",
       "1.0                          NaN              NaN         0.151395   \n",
       "0.1                          NaN              NaN         0.159201   \n",
       "0.001                        NaN              NaN         0.358484   \n",
       "\n",
       "                    Tiempo ejecución  \n",
       "Tasa de aprendizaje                   \n",
       "1.0                          0.20188  \n",
       "0.1                         0.157913  \n",
       "0.001                        0.10094  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meKODnJIhBwe"
   },
   "source": [
    "# Árbol de decisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yvt3O0plhN2g"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AG46ls4MgmtN"
   },
   "outputs": [],
   "source": [
    "def arbol_decision(prof):\n",
    "    if(prof == 0):\n",
    "        DT_model = DT(max_depth=None) \n",
    "    else:\n",
    "        DT_model = DT(max_depth = prof)\n",
    "    \n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    Errores = np.ones(100)\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    j=0\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(bagOfWords,y)   #Realiza una única partición de la base de datos\n",
    "\n",
    "        DT_model.fit(Xtrain,Ytrain)\n",
    "        Yest = DT_model.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(DT_model.score(Xtest,Ytest))\n",
    "        \n",
    "        Errores[j] = classification_error(Yest, Ytest)\n",
    "        j+=1\n",
    "\n",
    "    #print(\"Accuracy: \", np.mean(acc), \"+/-\", np.std(acc))\n",
    "    #print(\"Sensitivity: \", np.mean(sens), \"+/-\", np.std(sens))\n",
    "    #print(\"Especificity: \", np.mean(esp), \"+/-\", np.std(esp))\n",
    "    return np.mean(acc), np.std(acc), np.mean(sens), np.std(sens), np.mean(esp), np.std(esp),np.mean(Errores), time.time()-tiempo_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNNXsOT9KA0t"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add850f0805141798237d60e9420fd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Maxima profundidad' : pd.Series([0, 5,10,20,30,50,60,70])})\n",
    "\n",
    "df_types[\"Accuracy\"] = \"\"\n",
    "df_types[\"Int_Accuracy\"] = \"\"\n",
    "df_types[\"Sensibility\"] = \"\"\n",
    "df_types[\"Int_Sensibility\"] = \"\"\n",
    "df_types[\"Especificity\"] = \"\"\n",
    "df_types[\"Int_Especificity\"] = \"\"\n",
    "df_types[\"Error validación\"] = \"\"\n",
    "df_types[\"Tiempo ejecución\"] = \"\"\n",
    "df_types.set_index(['Maxima profundidad'], inplace=True)\n",
    "\n",
    "for i in df_types.index:\n",
    "    Acc, IntAcc, Sen, IntSen, Esp, IntEsp, error, tiempo=arbol_decision(i)       \n",
    "    df_types[\"Accuracy\"][i] = Acc\n",
    "    df_types[\"Int_Accuracy\"][i] = IntAcc\n",
    "    df_types[\"Sensibility\"][i] = Sen\n",
    "    df_types[\"Int_Sensibility\"][i] = IntSen\n",
    "    df_types[\"Especificity\"][i] = Esp\n",
    "    df_types[\"Int_Especificity\"][i] = IntEsp\n",
    "    df_types[\"Error validación\"][i] = error\n",
    "    df_types[\"Tiempo ejecución\"][i] = tiempo\n",
    "        \n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_84bbuIKA0z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Int_Accuracy</th>\n",
       "      <th>Sensibility</th>\n",
       "      <th>Int_Sensibility</th>\n",
       "      <th>Especificity</th>\n",
       "      <th>Int_Especificity</th>\n",
       "      <th>Error validación</th>\n",
       "      <th>Tiempo ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maxima profundidad</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.802171</td>\n",
       "      <td>0.0348489</td>\n",
       "      <td>0.779088</td>\n",
       "      <td>0.0503619</td>\n",
       "      <td>0.825685</td>\n",
       "      <td>0.0602123</td>\n",
       "      <td>0.197829</td>\n",
       "      <td>4.72729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.800465</td>\n",
       "      <td>0.0365185</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.0625269</td>\n",
       "      <td>0.852246</td>\n",
       "      <td>0.0840893</td>\n",
       "      <td>0.199535</td>\n",
       "      <td>2.72745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80155</td>\n",
       "      <td>0.0313546</td>\n",
       "      <td>0.759509</td>\n",
       "      <td>0.0543796</td>\n",
       "      <td>0.844628</td>\n",
       "      <td>0.055609</td>\n",
       "      <td>0.19845</td>\n",
       "      <td>3.75385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.805736</td>\n",
       "      <td>0.0309655</td>\n",
       "      <td>0.783405</td>\n",
       "      <td>0.0533935</td>\n",
       "      <td>0.829808</td>\n",
       "      <td>0.0579112</td>\n",
       "      <td>0.194264</td>\n",
       "      <td>4.38047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.803643</td>\n",
       "      <td>0.0359117</td>\n",
       "      <td>0.794622</td>\n",
       "      <td>0.0524795</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>0.0606948</td>\n",
       "      <td>0.196357</td>\n",
       "      <td>4.63034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.806977</td>\n",
       "      <td>0.0347456</td>\n",
       "      <td>0.786265</td>\n",
       "      <td>0.0477601</td>\n",
       "      <td>0.828607</td>\n",
       "      <td>0.0599895</td>\n",
       "      <td>0.193023</td>\n",
       "      <td>4.58037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.800233</td>\n",
       "      <td>0.0319405</td>\n",
       "      <td>0.775901</td>\n",
       "      <td>0.0507578</td>\n",
       "      <td>0.826427</td>\n",
       "      <td>0.0587196</td>\n",
       "      <td>0.199767</td>\n",
       "      <td>4.5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.805891</td>\n",
       "      <td>0.0303995</td>\n",
       "      <td>0.789353</td>\n",
       "      <td>0.0513622</td>\n",
       "      <td>0.822103</td>\n",
       "      <td>0.0524168</td>\n",
       "      <td>0.194109</td>\n",
       "      <td>4.94414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy Int_Accuracy Sensibility Int_Sensibility  \\\n",
       "Maxima profundidad                                                      \n",
       "0                   0.802171    0.0348489    0.779088       0.0503619   \n",
       "5                   0.800465    0.0365185      0.7507       0.0625269   \n",
       "10                   0.80155    0.0313546    0.759509       0.0543796   \n",
       "20                  0.805736    0.0309655    0.783405       0.0533935   \n",
       "30                  0.803643    0.0359117    0.794622       0.0524795   \n",
       "50                  0.806977    0.0347456    0.786265       0.0477601   \n",
       "60                  0.800233    0.0319405    0.775901       0.0507578   \n",
       "70                  0.805891    0.0303995    0.789353       0.0513622   \n",
       "\n",
       "                   Especificity Int_Especificity Error validación  \\\n",
       "Maxima profundidad                                                  \n",
       "0                      0.825685        0.0602123         0.197829   \n",
       "5                      0.852246        0.0840893         0.199535   \n",
       "10                     0.844628         0.055609          0.19845   \n",
       "20                     0.829808        0.0579112         0.194264   \n",
       "30                       0.8141        0.0606948         0.196357   \n",
       "50                     0.828607        0.0599895         0.193023   \n",
       "60                     0.826427        0.0587196         0.199767   \n",
       "70                     0.822103        0.0524168         0.194109   \n",
       "\n",
       "                   Tiempo ejecución  \n",
       "Maxima profundidad                   \n",
       "0                           4.72729  \n",
       "5                           2.72745  \n",
       "10                          3.75385  \n",
       "20                          4.38047  \n",
       "30                          4.63034  \n",
       "50                          4.58037  \n",
       "60                           4.5554  \n",
       "70                          4.94414  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crpuYZTUfjh4"
   },
   "source": [
    "# Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXPSyZlhljBJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7r_BLa_fsgm"
   },
   "outputs": [],
   "source": [
    "def random_forest(est, carac):\n",
    "    \n",
    "    RF_model = RF(n_estimators=est, max_features =carac)\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    Errores = np.ones(100)\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    j=0\n",
    "\n",
    "    for i in range(100):\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(bagOfWords,y)   #Realiza una única partición de la base de datos\n",
    "\n",
    "        RF_model.fit(Xtrain,Ytrain)\n",
    "        Yest = RF_model.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(RF_model.score(Xtest,Ytest))\n",
    "        Errores[j] = classification_error(Yest, Ytest)\n",
    "        j+=1\n",
    "        \n",
    "    return np.mean(acc), np.std(acc), np.mean(sens), np.std(sens), np.mean(esp), np.std(esp),np.mean(Errores), time.time()-tiempo_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETLQ6trQKA1D"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4e1bac5c194f84aecbeeb8e951e93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Numero de arboles' : pd.Series([5,5,5,5,5,5,10,10,10,10,10,10,20,20,20,20,20,20,50,50,50,50,50,50,100,100,100,100,100,100]), \n",
    "    'Variables analizadas por nodo' : pd.Series([50,100,150,200,250,300,50,100,150,200,250,300,50,100,150,200,250,300,50,100,150,200,250,300,50,100,150,200,250,300])})\n",
    "\n",
    "df_types[\"Accuracy\"] = \"\"\n",
    "df_types[\"Int_Accuracy\"] = \"\"\n",
    "df_types[\"Sensibility\"] = \"\"\n",
    "df_types[\"Int_Sensibility\"] = \"\"\n",
    "df_types[\"Especificity\"] = \"\"\n",
    "df_types[\"Int_Especificity\"] = \"\"\n",
    "df_types[\"Error validación\"] = \"\"\n",
    "df_types[\"Tiempo ejecución\"] = \"\"\n",
    "df_types.set_index(['Numero de arboles', 'Variables analizadas por nodo'], inplace=True)\n",
    "\n",
    "for i in df_types.index:\n",
    "    Acc, IntAcc, Sen, IntSen, Esp, IntEsp, error, tiempo=random_forest(i[0], i[1])       \n",
    "    df_types[\"Accuracy\"][i] = Acc\n",
    "    df_types[\"Int_Accuracy\"][i] = IntAcc\n",
    "    df_types[\"Sensibility\"][i] = Sen\n",
    "    df_types[\"Int_Sensibility\"][i] = IntSen\n",
    "    df_types[\"Especificity\"][i] = Esp\n",
    "    df_types[\"Int_Especificity\"][i] = IntEsp\n",
    "    df_types[\"Error validación\"][i] = error\n",
    "    df_types[\"Tiempo ejecución\"][i] = tiempo\n",
    "        \n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxoIPc6SKA1J"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Int_Accuracy</th>\n",
       "      <th>Sensibility</th>\n",
       "      <th>Int_Sensibility</th>\n",
       "      <th>Especificity</th>\n",
       "      <th>Int_Especificity</th>\n",
       "      <th>Error validación</th>\n",
       "      <th>Tiempo ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Numero de arboles</th>\n",
       "      <th>Variables analizadas por nodo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th>50</th>\n",
       "      <td>0.786357</td>\n",
       "      <td>0.0425343</td>\n",
       "      <td>0.822353</td>\n",
       "      <td>0.0704729</td>\n",
       "      <td>0.75276</td>\n",
       "      <td>0.0958447</td>\n",
       "      <td>0.213643</td>\n",
       "      <td>3.18019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.791395</td>\n",
       "      <td>0.0382147</td>\n",
       "      <td>0.810732</td>\n",
       "      <td>0.0643881</td>\n",
       "      <td>0.774449</td>\n",
       "      <td>0.0778693</td>\n",
       "      <td>0.208605</td>\n",
       "      <td>3.23714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.810078</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.824075</td>\n",
       "      <td>0.0634696</td>\n",
       "      <td>0.797756</td>\n",
       "      <td>0.0698174</td>\n",
       "      <td>0.189922</td>\n",
       "      <td>3.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.804729</td>\n",
       "      <td>0.036733</td>\n",
       "      <td>0.818463</td>\n",
       "      <td>0.0653143</td>\n",
       "      <td>0.793343</td>\n",
       "      <td>0.06826</td>\n",
       "      <td>0.195271</td>\n",
       "      <td>3.86678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.809225</td>\n",
       "      <td>0.0340008</td>\n",
       "      <td>0.829444</td>\n",
       "      <td>0.0655292</td>\n",
       "      <td>0.790531</td>\n",
       "      <td>0.0704338</td>\n",
       "      <td>0.190775</td>\n",
       "      <td>4.1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.809845</td>\n",
       "      <td>0.0329153</td>\n",
       "      <td>0.806363</td>\n",
       "      <td>0.0657303</td>\n",
       "      <td>0.814561</td>\n",
       "      <td>0.0723311</td>\n",
       "      <td>0.190155</td>\n",
       "      <td>4.13861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10</th>\n",
       "      <th>50</th>\n",
       "      <td>0.820388</td>\n",
       "      <td>0.0338087</td>\n",
       "      <td>0.800816</td>\n",
       "      <td>0.0671238</td>\n",
       "      <td>0.842629</td>\n",
       "      <td>0.0742029</td>\n",
       "      <td>0.179612</td>\n",
       "      <td>5.30397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.831085</td>\n",
       "      <td>0.0309941</td>\n",
       "      <td>0.802674</td>\n",
       "      <td>0.0521096</td>\n",
       "      <td>0.863315</td>\n",
       "      <td>0.0593756</td>\n",
       "      <td>0.168915</td>\n",
       "      <td>6.09848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.832171</td>\n",
       "      <td>0.036432</td>\n",
       "      <td>0.803702</td>\n",
       "      <td>0.0709142</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>0.0681324</td>\n",
       "      <td>0.167829</td>\n",
       "      <td>6.33838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.836202</td>\n",
       "      <td>0.0377807</td>\n",
       "      <td>0.799591</td>\n",
       "      <td>0.0723005</td>\n",
       "      <td>0.876155</td>\n",
       "      <td>0.0579356</td>\n",
       "      <td>0.163798</td>\n",
       "      <td>6.93101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.832946</td>\n",
       "      <td>0.036399</td>\n",
       "      <td>0.802205</td>\n",
       "      <td>0.0645843</td>\n",
       "      <td>0.86657</td>\n",
       "      <td>0.0618076</td>\n",
       "      <td>0.167054</td>\n",
       "      <td>7.42775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.83814</td>\n",
       "      <td>0.0262945</td>\n",
       "      <td>0.809419</td>\n",
       "      <td>0.0636516</td>\n",
       "      <td>0.870615</td>\n",
       "      <td>0.0618241</td>\n",
       "      <td>0.16186</td>\n",
       "      <td>7.73156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">20</th>\n",
       "      <th>50</th>\n",
       "      <td>0.85845</td>\n",
       "      <td>0.0296732</td>\n",
       "      <td>0.871437</td>\n",
       "      <td>0.0502087</td>\n",
       "      <td>0.8487</td>\n",
       "      <td>0.0631296</td>\n",
       "      <td>0.14155</td>\n",
       "      <td>10.2571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.852093</td>\n",
       "      <td>0.0311948</td>\n",
       "      <td>0.84695</td>\n",
       "      <td>0.0539085</td>\n",
       "      <td>0.860105</td>\n",
       "      <td>0.0592262</td>\n",
       "      <td>0.147907</td>\n",
       "      <td>11.4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.85124</td>\n",
       "      <td>0.0309825</td>\n",
       "      <td>0.840588</td>\n",
       "      <td>0.0564395</td>\n",
       "      <td>0.863901</td>\n",
       "      <td>0.0630851</td>\n",
       "      <td>0.14876</td>\n",
       "      <td>12.8276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.858527</td>\n",
       "      <td>0.0308985</td>\n",
       "      <td>0.847917</td>\n",
       "      <td>0.0543829</td>\n",
       "      <td>0.871395</td>\n",
       "      <td>0.052618</td>\n",
       "      <td>0.141473</td>\n",
       "      <td>13.5392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.852791</td>\n",
       "      <td>0.0295489</td>\n",
       "      <td>0.83541</td>\n",
       "      <td>0.0603981</td>\n",
       "      <td>0.871843</td>\n",
       "      <td>0.0500327</td>\n",
       "      <td>0.147209</td>\n",
       "      <td>14.3108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.849922</td>\n",
       "      <td>0.0287245</td>\n",
       "      <td>0.839185</td>\n",
       "      <td>0.0480671</td>\n",
       "      <td>0.862542</td>\n",
       "      <td>0.0556366</td>\n",
       "      <td>0.150078</td>\n",
       "      <td>15.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">50</th>\n",
       "      <th>50</th>\n",
       "      <td>0.867752</td>\n",
       "      <td>0.0290221</td>\n",
       "      <td>0.888809</td>\n",
       "      <td>0.0470448</td>\n",
       "      <td>0.850294</td>\n",
       "      <td>0.0681565</td>\n",
       "      <td>0.132248</td>\n",
       "      <td>24.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.866434</td>\n",
       "      <td>0.0254248</td>\n",
       "      <td>0.873238</td>\n",
       "      <td>0.0512398</td>\n",
       "      <td>0.862557</td>\n",
       "      <td>0.0603822</td>\n",
       "      <td>0.133566</td>\n",
       "      <td>27.4323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.864961</td>\n",
       "      <td>0.0290709</td>\n",
       "      <td>0.867091</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>0.865919</td>\n",
       "      <td>0.0627022</td>\n",
       "      <td>0.135039</td>\n",
       "      <td>30.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.862791</td>\n",
       "      <td>0.0315743</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.0461762</td>\n",
       "      <td>0.867934</td>\n",
       "      <td>0.0618977</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>32.9341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.0284191</td>\n",
       "      <td>0.870586</td>\n",
       "      <td>0.0473353</td>\n",
       "      <td>0.865155</td>\n",
       "      <td>0.0511335</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>34.4592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.861473</td>\n",
       "      <td>0.0310204</td>\n",
       "      <td>0.862261</td>\n",
       "      <td>0.0490319</td>\n",
       "      <td>0.864219</td>\n",
       "      <td>0.0558331</td>\n",
       "      <td>0.138527</td>\n",
       "      <td>36.4171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">100</th>\n",
       "      <th>50</th>\n",
       "      <td>0.879302</td>\n",
       "      <td>0.0284667</td>\n",
       "      <td>0.89789</td>\n",
       "      <td>0.0436253</td>\n",
       "      <td>0.863637</td>\n",
       "      <td>0.0601469</td>\n",
       "      <td>0.120698</td>\n",
       "      <td>50.9378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.866279</td>\n",
       "      <td>0.0322685</td>\n",
       "      <td>0.882121</td>\n",
       "      <td>0.0535201</td>\n",
       "      <td>0.854187</td>\n",
       "      <td>0.0642322</td>\n",
       "      <td>0.133721</td>\n",
       "      <td>62.3792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.867984</td>\n",
       "      <td>0.0305677</td>\n",
       "      <td>0.877413</td>\n",
       "      <td>0.0452968</td>\n",
       "      <td>0.861795</td>\n",
       "      <td>0.0613479</td>\n",
       "      <td>0.132016</td>\n",
       "      <td>71.6619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.869767</td>\n",
       "      <td>0.0267189</td>\n",
       "      <td>0.870806</td>\n",
       "      <td>0.0479484</td>\n",
       "      <td>0.87258</td>\n",
       "      <td>0.0553931</td>\n",
       "      <td>0.130233</td>\n",
       "      <td>76.2412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.85969</td>\n",
       "      <td>0.0259314</td>\n",
       "      <td>0.859345</td>\n",
       "      <td>0.0463602</td>\n",
       "      <td>0.863096</td>\n",
       "      <td>0.0571654</td>\n",
       "      <td>0.14031</td>\n",
       "      <td>73.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.867752</td>\n",
       "      <td>0.0300395</td>\n",
       "      <td>0.873163</td>\n",
       "      <td>0.0484346</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.0618981</td>\n",
       "      <td>0.132248</td>\n",
       "      <td>75.6356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy Int_Accuracy  \\\n",
       "Numero de arboles Variables analizadas por nodo                          \n",
       "5                 50                             0.786357    0.0425343   \n",
       "                  100                            0.791395    0.0382147   \n",
       "                  150                            0.810078     0.035583   \n",
       "                  200                            0.804729     0.036733   \n",
       "                  250                            0.809225    0.0340008   \n",
       "                  300                            0.809845    0.0329153   \n",
       "10                50                             0.820388    0.0338087   \n",
       "                  100                            0.831085    0.0309941   \n",
       "                  150                            0.832171     0.036432   \n",
       "                  200                            0.836202    0.0377807   \n",
       "                  250                            0.832946     0.036399   \n",
       "                  300                             0.83814    0.0262945   \n",
       "20                50                              0.85845    0.0296732   \n",
       "                  100                            0.852093    0.0311948   \n",
       "                  150                             0.85124    0.0309825   \n",
       "                  200                            0.858527    0.0308985   \n",
       "                  250                            0.852791    0.0295489   \n",
       "                  300                            0.849922    0.0287245   \n",
       "50                50                             0.867752    0.0290221   \n",
       "                  100                            0.866434    0.0254248   \n",
       "                  150                            0.864961    0.0290709   \n",
       "                  200                            0.862791    0.0315743   \n",
       "                  250                            0.866667    0.0284191   \n",
       "                  300                            0.861473    0.0310204   \n",
       "100               50                             0.879302    0.0284667   \n",
       "                  100                            0.866279    0.0322685   \n",
       "                  150                            0.867984    0.0305677   \n",
       "                  200                            0.869767    0.0267189   \n",
       "                  250                             0.85969    0.0259314   \n",
       "                  300                            0.867752    0.0300395   \n",
       "\n",
       "                                                Sensibility Int_Sensibility  \\\n",
       "Numero de arboles Variables analizadas por nodo                               \n",
       "5                 50                               0.822353       0.0704729   \n",
       "                  100                              0.810732       0.0643881   \n",
       "                  150                              0.824075       0.0634696   \n",
       "                  200                              0.818463       0.0653143   \n",
       "                  250                              0.829444       0.0655292   \n",
       "                  300                              0.806363       0.0657303   \n",
       "10                50                               0.800816       0.0671238   \n",
       "                  100                              0.802674       0.0521096   \n",
       "                  150                              0.803702       0.0709142   \n",
       "                  200                              0.799591       0.0723005   \n",
       "                  250                              0.802205       0.0645843   \n",
       "                  300                              0.809419       0.0636516   \n",
       "20                50                               0.871437       0.0502087   \n",
       "                  100                               0.84695       0.0539085   \n",
       "                  150                              0.840588       0.0564395   \n",
       "                  200                              0.847917       0.0543829   \n",
       "                  250                               0.83541       0.0603981   \n",
       "                  300                              0.839185       0.0480671   \n",
       "50                50                               0.888809       0.0470448   \n",
       "                  100                              0.873238       0.0512398   \n",
       "                  150                              0.867091        0.049484   \n",
       "                  200                              0.860349       0.0461762   \n",
       "                  250                              0.870586       0.0473353   \n",
       "                  300                              0.862261       0.0490319   \n",
       "100               50                                0.89789       0.0436253   \n",
       "                  100                              0.882121       0.0535201   \n",
       "                  150                              0.877413       0.0452968   \n",
       "                  200                              0.870806       0.0479484   \n",
       "                  250                              0.859345       0.0463602   \n",
       "                  300                              0.873163       0.0484346   \n",
       "\n",
       "                                                Especificity Int_Especificity  \\\n",
       "Numero de arboles Variables analizadas por nodo                                 \n",
       "5                 50                                 0.75276        0.0958447   \n",
       "                  100                               0.774449        0.0778693   \n",
       "                  150                               0.797756        0.0698174   \n",
       "                  200                               0.793343          0.06826   \n",
       "                  250                               0.790531        0.0704338   \n",
       "                  300                               0.814561        0.0723311   \n",
       "10                50                                0.842629        0.0742029   \n",
       "                  100                               0.863315        0.0593756   \n",
       "                  150                               0.865229        0.0681324   \n",
       "                  200                               0.876155        0.0579356   \n",
       "                  250                                0.86657        0.0618076   \n",
       "                  300                               0.870615        0.0618241   \n",
       "20                50                                  0.8487        0.0631296   \n",
       "                  100                               0.860105        0.0592262   \n",
       "                  150                               0.863901        0.0630851   \n",
       "                  200                               0.871395         0.052618   \n",
       "                  250                               0.871843        0.0500327   \n",
       "                  300                               0.862542        0.0556366   \n",
       "50                50                                0.850294        0.0681565   \n",
       "                  100                               0.862557        0.0603822   \n",
       "                  150                               0.865919        0.0627022   \n",
       "                  200                               0.867934        0.0618977   \n",
       "                  250                               0.865155        0.0511335   \n",
       "                  300                               0.864219        0.0558331   \n",
       "100               50                                0.863637        0.0601469   \n",
       "                  100                               0.854187        0.0642322   \n",
       "                  150                               0.861795        0.0613479   \n",
       "                  200                                0.87258        0.0553931   \n",
       "                  250                               0.863096        0.0571654   \n",
       "                  300                               0.865449        0.0618981   \n",
       "\n",
       "                                                Error validación  \\\n",
       "Numero de arboles Variables analizadas por nodo                    \n",
       "5                 50                                    0.213643   \n",
       "                  100                                   0.208605   \n",
       "                  150                                   0.189922   \n",
       "                  200                                   0.195271   \n",
       "                  250                                   0.190775   \n",
       "                  300                                   0.190155   \n",
       "10                50                                    0.179612   \n",
       "                  100                                   0.168915   \n",
       "                  150                                   0.167829   \n",
       "                  200                                   0.163798   \n",
       "                  250                                   0.167054   \n",
       "                  300                                    0.16186   \n",
       "20                50                                     0.14155   \n",
       "                  100                                   0.147907   \n",
       "                  150                                    0.14876   \n",
       "                  200                                   0.141473   \n",
       "                  250                                   0.147209   \n",
       "                  300                                   0.150078   \n",
       "50                50                                    0.132248   \n",
       "                  100                                   0.133566   \n",
       "                  150                                   0.135039   \n",
       "                  200                                   0.137209   \n",
       "                  250                                   0.133333   \n",
       "                  300                                   0.138527   \n",
       "100               50                                    0.120698   \n",
       "                  100                                   0.133721   \n",
       "                  150                                   0.132016   \n",
       "                  200                                   0.130233   \n",
       "                  250                                    0.14031   \n",
       "                  300                                   0.132248   \n",
       "\n",
       "                                                Tiempo ejecución  \n",
       "Numero de arboles Variables analizadas por nodo                   \n",
       "5                 50                                     3.18019  \n",
       "                  100                                    3.23714  \n",
       "                  150                                      3.485  \n",
       "                  200                                    3.86678  \n",
       "                  250                                     4.1806  \n",
       "                  300                                    4.13861  \n",
       "10                50                                     5.30397  \n",
       "                  100                                    6.09848  \n",
       "                  150                                    6.33838  \n",
       "                  200                                    6.93101  \n",
       "                  250                                    7.42775  \n",
       "                  300                                    7.73156  \n",
       "20                50                                     10.2571  \n",
       "                  100                                    11.4584  \n",
       "                  150                                    12.8276  \n",
       "                  200                                    13.5392  \n",
       "                  250                                    14.3108  \n",
       "                  300                                    15.0534  \n",
       "50                50                                     24.9517  \n",
       "                  100                                    27.4323  \n",
       "                  150                                    30.0407  \n",
       "                  200                                    32.9341  \n",
       "                  250                                    34.4592  \n",
       "                  300                                    36.4171  \n",
       "100               50                                     50.9378  \n",
       "                  100                                    62.3792  \n",
       "                  150                                    71.6619  \n",
       "                  200                                    76.2412  \n",
       "                  250                                     73.195  \n",
       "                  300                                    75.6356  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KHOKHUjcrnDO"
   },
   "source": [
    "# Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7trMj6JUrsi1"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtCIl9Gxrx3E"
   },
   "outputs": [],
   "source": [
    "def SVM (ker, c, gam): \n",
    "    \n",
    "    if gam == 0:\n",
    "        gam = 'auto'\n",
    "    \n",
    "    svm_model =svm.SVC(kernel=ker, C=c, gamma=gam)\n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    Errores = np.ones(100)\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    j=0\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(bagOfWords,y)   #Realiza una única partición de la base de datos\n",
    "\n",
    "        svm_model.fit(Xtrain,Ytrain)\n",
    "        Yest = svm_model.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(svm_model.score(Xtest,Ytest))\n",
    "        Errores[j] = classification_error(Yest, Ytest)\n",
    "        j+=1\n",
    "\n",
    "    return np.mean(acc), np.std(acc), np.mean(sens), np.std(sens), np.mean(esp), np.std(esp),np.mean(Errores), time.time()-tiempo_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T23T9AlCKA1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7f8e0adee648f689386271c21fddbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'Kernel' : pd.Series(['linear','linear','linear','linear','linear','linear','linear','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf','rbf', 'rbf']),\n",
    "    'C' : pd.Series([0.001,0.01,0.1,1,10,100,200,0.001,0.001,0.001,0.001,0.01,0.01,0.01,0.01,0.1,0.1,0.1,0.1,1,1,1,1,10,10,10,10,100,100,100,100,200,200,200,200]),\n",
    "    'gamma' : pd.Series([0,0,0,0,0,0,0,0.001,0.01,0.1,1,0.001,0.01,0.1,1,0.001,0.01,0.1,1,0.001,0.01,0.1,1,0.001,0.01,0.1,1,0.001,0.01,0.1,1,0.001,0.01,0.1,1])})\n",
    "\n",
    "df_types[\"Accuracy\"] = \"\"\n",
    "df_types[\"Int_Accuracy\"] = \"\"\n",
    "df_types[\"Sensibility\"] = \"\"\n",
    "df_types[\"Int_Sensibility\"] = \"\"\n",
    "df_types[\"Especificity\"] = \"\"\n",
    "df_types[\"Int_Especificity\"] = \"\"\n",
    "df_types[\"Error validación\"] = \"\"\n",
    "df_types[\"Tiempo ejecución\"] = \"\"\n",
    "df_types.set_index(['Kernel','C','gamma'], inplace=True)\n",
    "\n",
    "for i in df_types.index:\n",
    "    Acc, IntAcc, Sen, IntSen, Esp, IntEsp, error, tiempo=SVM(i[0], i[1], i[2])       \n",
    "    df_types[\"Accuracy\"][i] = Acc\n",
    "    df_types[\"Int_Accuracy\"][i] = IntAcc\n",
    "    df_types[\"Sensibility\"][i] = Sen\n",
    "    df_types[\"Int_Sensibility\"][i] = IntSen\n",
    "    df_types[\"Especificity\"][i] = Esp\n",
    "    df_types[\"Int_Especificity\"][i] = IntEsp\n",
    "    df_types[\"Error validación\"][i] = error\n",
    "    df_types[\"Tiempo ejecución\"][i] = tiempo\n",
    "        \n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1h3njglKA1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Int_Accuracy</th>\n",
       "      <th>Sensibility</th>\n",
       "      <th>Int_Sensibility</th>\n",
       "      <th>Especificity</th>\n",
       "      <th>Int_Especificity</th>\n",
       "      <th>Error validación</th>\n",
       "      <th>Tiempo ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">linear</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.615426</td>\n",
       "      <td>0.0962109</td>\n",
       "      <td>0.902022</td>\n",
       "      <td>0.224224</td>\n",
       "      <td>0.354837</td>\n",
       "      <td>0.282498</td>\n",
       "      <td>0.384574</td>\n",
       "      <td>10.8988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.803023</td>\n",
       "      <td>0.0400423</td>\n",
       "      <td>0.933274</td>\n",
       "      <td>0.0324979</td>\n",
       "      <td>0.673946</td>\n",
       "      <td>0.0662476</td>\n",
       "      <td>0.196977</td>\n",
       "      <td>7.95344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.871163</td>\n",
       "      <td>0.0287508</td>\n",
       "      <td>0.904292</td>\n",
       "      <td>0.0382995</td>\n",
       "      <td>0.839947</td>\n",
       "      <td>0.0503959</td>\n",
       "      <td>0.128837</td>\n",
       "      <td>7.12892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.881395</td>\n",
       "      <td>0.0266175</td>\n",
       "      <td>0.894198</td>\n",
       "      <td>0.039705</td>\n",
       "      <td>0.870449</td>\n",
       "      <td>0.04176</td>\n",
       "      <td>0.118605</td>\n",
       "      <td>7.24083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.875814</td>\n",
       "      <td>0.0260811</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>0.0413947</td>\n",
       "      <td>0.863173</td>\n",
       "      <td>0.0444681</td>\n",
       "      <td>0.124186</td>\n",
       "      <td>7.23485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.877597</td>\n",
       "      <td>0.0269494</td>\n",
       "      <td>0.891442</td>\n",
       "      <td>0.040678</td>\n",
       "      <td>0.864878</td>\n",
       "      <td>0.0403132</td>\n",
       "      <td>0.122403</td>\n",
       "      <td>7.30681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200.000</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.88031</td>\n",
       "      <td>0.0254358</td>\n",
       "      <td>0.885681</td>\n",
       "      <td>0.0399255</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.0417564</td>\n",
       "      <td>0.11969</td>\n",
       "      <td>7.18888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"28\" valign=\"top\">rbf</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.472791</td>\n",
       "      <td>0.0242053</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.527209</td>\n",
       "      <td>10.2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.467519</td>\n",
       "      <td>0.0269137</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.532481</td>\n",
       "      <td>10.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.47031</td>\n",
       "      <td>0.0244415</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.498397</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.498397</td>\n",
       "      <td>0.52969</td>\n",
       "      <td>11.9292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.471938</td>\n",
       "      <td>0.0228723</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.497494</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.497494</td>\n",
       "      <td>0.528062</td>\n",
       "      <td>10.9597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.010</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.468372</td>\n",
       "      <td>0.0266779</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.491833</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.491833</td>\n",
       "      <td>0.531628</td>\n",
       "      <td>10.2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.470465</td>\n",
       "      <td>0.0235816</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.493559</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.493559</td>\n",
       "      <td>0.529535</td>\n",
       "      <td>10.2131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.466589</td>\n",
       "      <td>0.0245308</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.498397</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.498397</td>\n",
       "      <td>0.533411</td>\n",
       "      <td>10.3361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.469535</td>\n",
       "      <td>0.0227399</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.530465</td>\n",
       "      <td>10.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.100</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.469845</td>\n",
       "      <td>0.0209129</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.496387</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.496387</td>\n",
       "      <td>0.530155</td>\n",
       "      <td>10.0852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.654729</td>\n",
       "      <td>0.0587556</td>\n",
       "      <td>0.808776</td>\n",
       "      <td>0.150998</td>\n",
       "      <td>0.517144</td>\n",
       "      <td>0.170315</td>\n",
       "      <td>0.345271</td>\n",
       "      <td>10.2191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.47093</td>\n",
       "      <td>0.0258821</td>\n",
       "      <td>0.521481</td>\n",
       "      <td>0.498081</td>\n",
       "      <td>0.480774</td>\n",
       "      <td>0.498549</td>\n",
       "      <td>0.52907</td>\n",
       "      <td>10.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.47031</td>\n",
       "      <td>0.0211744</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>0.52969</td>\n",
       "      <td>10.6459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.000</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0608169</td>\n",
       "      <td>0.945392</td>\n",
       "      <td>0.0313425</td>\n",
       "      <td>0.440688</td>\n",
       "      <td>0.0981723</td>\n",
       "      <td>0.31</td>\n",
       "      <td>9.60549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.822481</td>\n",
       "      <td>0.0312875</td>\n",
       "      <td>0.895011</td>\n",
       "      <td>0.0386019</td>\n",
       "      <td>0.752335</td>\n",
       "      <td>0.051423</td>\n",
       "      <td>0.177519</td>\n",
       "      <td>8.59407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.706822</td>\n",
       "      <td>0.0476146</td>\n",
       "      <td>0.555919</td>\n",
       "      <td>0.0769925</td>\n",
       "      <td>0.863065</td>\n",
       "      <td>0.0520329</td>\n",
       "      <td>0.293178</td>\n",
       "      <td>10.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.48155</td>\n",
       "      <td>0.0297674</td>\n",
       "      <td>0.686545</td>\n",
       "      <td>0.457107</td>\n",
       "      <td>0.332041</td>\n",
       "      <td>0.457712</td>\n",
       "      <td>0.51845</td>\n",
       "      <td>10.9337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10.000</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.835271</td>\n",
       "      <td>0.0319503</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>0.0286763</td>\n",
       "      <td>0.749582</td>\n",
       "      <td>0.0645792</td>\n",
       "      <td>0.164729</td>\n",
       "      <td>7.20986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.873643</td>\n",
       "      <td>0.0261621</td>\n",
       "      <td>0.866161</td>\n",
       "      <td>0.0447594</td>\n",
       "      <td>0.881978</td>\n",
       "      <td>0.0401922</td>\n",
       "      <td>0.126357</td>\n",
       "      <td>9.15675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.737442</td>\n",
       "      <td>0.0368793</td>\n",
       "      <td>0.562955</td>\n",
       "      <td>0.0538452</td>\n",
       "      <td>0.91342</td>\n",
       "      <td>0.0373407</td>\n",
       "      <td>0.262558</td>\n",
       "      <td>10.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.479225</td>\n",
       "      <td>0.0266148</td>\n",
       "      <td>0.509477</td>\n",
       "      <td>0.489755</td>\n",
       "      <td>0.508492</td>\n",
       "      <td>0.48684</td>\n",
       "      <td>0.520775</td>\n",
       "      <td>11.1246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100.000</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.885581</td>\n",
       "      <td>0.0279311</td>\n",
       "      <td>0.89312</td>\n",
       "      <td>0.0375383</td>\n",
       "      <td>0.878543</td>\n",
       "      <td>0.0441475</td>\n",
       "      <td>0.114419</td>\n",
       "      <td>7.45273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.877132</td>\n",
       "      <td>0.0237005</td>\n",
       "      <td>0.86643</td>\n",
       "      <td>0.0429889</td>\n",
       "      <td>0.888776</td>\n",
       "      <td>0.0388304</td>\n",
       "      <td>0.122868</td>\n",
       "      <td>9.07679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.737442</td>\n",
       "      <td>0.0392168</td>\n",
       "      <td>0.569822</td>\n",
       "      <td>0.0632382</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>0.0406909</td>\n",
       "      <td>0.262558</td>\n",
       "      <td>10.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.47907</td>\n",
       "      <td>0.0256635</td>\n",
       "      <td>0.608418</td>\n",
       "      <td>0.479725</td>\n",
       "      <td>0.406325</td>\n",
       "      <td>0.476495</td>\n",
       "      <td>0.52093</td>\n",
       "      <td>11.1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">200.000</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.877829</td>\n",
       "      <td>0.0291728</td>\n",
       "      <td>0.881611</td>\n",
       "      <td>0.0468658</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>0.0501855</td>\n",
       "      <td>0.122171</td>\n",
       "      <td>7.25084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.879845</td>\n",
       "      <td>0.0262767</td>\n",
       "      <td>0.873358</td>\n",
       "      <td>0.0388246</td>\n",
       "      <td>0.886942</td>\n",
       "      <td>0.0429939</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>9.09078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.727442</td>\n",
       "      <td>0.0387863</td>\n",
       "      <td>0.550693</td>\n",
       "      <td>0.058042</td>\n",
       "      <td>0.912648</td>\n",
       "      <td>0.0356647</td>\n",
       "      <td>0.272558</td>\n",
       "      <td>10.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.477829</td>\n",
       "      <td>0.0293044</td>\n",
       "      <td>0.548152</td>\n",
       "      <td>0.488509</td>\n",
       "      <td>0.469836</td>\n",
       "      <td>0.487189</td>\n",
       "      <td>0.522171</td>\n",
       "      <td>11.1516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy Int_Accuracy Sensibility Int_Sensibility  \\\n",
       "Kernel C       gamma                                                      \n",
       "linear 0.001   0.000  0.615426    0.0962109    0.902022        0.224224   \n",
       "       0.010   0.000  0.803023    0.0400423    0.933274       0.0324979   \n",
       "       0.100   0.000  0.871163    0.0287508    0.904292       0.0382995   \n",
       "       1.000   0.000  0.881395    0.0266175    0.894198        0.039705   \n",
       "       10.000  0.000  0.875814    0.0260811    0.889475       0.0413947   \n",
       "       100.000 0.000  0.877597    0.0269494    0.891442        0.040678   \n",
       "       200.000 0.000   0.88031    0.0254358    0.885681       0.0399255   \n",
       "rbf    0.001   0.001  0.472791    0.0242053        0.62        0.485386   \n",
       "               0.010  0.467519    0.0269137        0.62        0.485386   \n",
       "               0.100   0.47031    0.0244415        0.54        0.498397   \n",
       "               1.000  0.471938    0.0228723        0.55        0.497494   \n",
       "       0.010   0.001  0.468372    0.0266779        0.59        0.491833   \n",
       "               0.010  0.470465    0.0235816        0.58        0.493559   \n",
       "               0.100  0.466589    0.0245308        0.54        0.498397   \n",
       "               1.000  0.469535    0.0227399        0.57        0.495076   \n",
       "       0.100   0.001  0.469845    0.0209129        0.56        0.496387   \n",
       "               0.010  0.654729    0.0587556    0.808776        0.150998   \n",
       "               0.100   0.47093    0.0258821    0.521481        0.498081   \n",
       "               1.000   0.47031    0.0211744        0.51          0.4999   \n",
       "       1.000   0.001      0.69    0.0608169    0.945392       0.0313425   \n",
       "               0.010  0.822481    0.0312875    0.895011       0.0386019   \n",
       "               0.100  0.706822    0.0476146    0.555919       0.0769925   \n",
       "               1.000   0.48155    0.0297674    0.686545        0.457107   \n",
       "       10.000  0.001  0.835271    0.0319503    0.921024       0.0286763   \n",
       "               0.010  0.873643    0.0261621    0.866161       0.0447594   \n",
       "               0.100  0.737442    0.0368793    0.562955       0.0538452   \n",
       "               1.000  0.479225    0.0266148    0.509477        0.489755   \n",
       "       100.000 0.001  0.885581    0.0279311     0.89312       0.0375383   \n",
       "               0.010  0.877132    0.0237005     0.86643       0.0429889   \n",
       "               0.100  0.737442    0.0392168    0.569822       0.0632382   \n",
       "               1.000   0.47907    0.0256635    0.608418        0.479725   \n",
       "       200.000 0.001  0.877829    0.0291728    0.881611       0.0468658   \n",
       "               0.010  0.879845    0.0262767    0.873358       0.0388246   \n",
       "               0.100  0.727442    0.0387863    0.550693        0.058042   \n",
       "               1.000  0.477829    0.0293044    0.548152        0.488509   \n",
       "\n",
       "                     Especificity Int_Especificity Error validación  \\\n",
       "Kernel C       gamma                                                  \n",
       "linear 0.001   0.000     0.354837         0.282498         0.384574   \n",
       "       0.010   0.000     0.673946        0.0662476         0.196977   \n",
       "       0.100   0.000     0.839947        0.0503959         0.128837   \n",
       "       1.000   0.000     0.870449          0.04176         0.118605   \n",
       "       10.000  0.000     0.863173        0.0444681         0.124186   \n",
       "       100.000 0.000     0.864878        0.0403132         0.122403   \n",
       "       200.000 0.000     0.875667        0.0417564          0.11969   \n",
       "rbf    0.001   0.001         0.38         0.485386         0.527209   \n",
       "               0.010         0.38         0.485386         0.532481   \n",
       "               0.100         0.46         0.498397          0.52969   \n",
       "               1.000         0.45         0.497494         0.528062   \n",
       "       0.010   0.001         0.41         0.491833         0.531628   \n",
       "               0.010         0.42         0.493559         0.529535   \n",
       "               0.100         0.46         0.498397         0.533411   \n",
       "               1.000         0.43         0.495076         0.530465   \n",
       "       0.100   0.001         0.44         0.496387         0.530155   \n",
       "               0.010     0.517144         0.170315         0.345271   \n",
       "               0.100     0.480774         0.498549          0.52907   \n",
       "               1.000         0.49           0.4999          0.52969   \n",
       "       1.000   0.001     0.440688        0.0981723             0.31   \n",
       "               0.010     0.752335         0.051423         0.177519   \n",
       "               0.100     0.863065        0.0520329         0.293178   \n",
       "               1.000     0.332041         0.457712          0.51845   \n",
       "       10.000  0.001     0.749582        0.0645792         0.164729   \n",
       "               0.010     0.881978        0.0401922         0.126357   \n",
       "               0.100      0.91342        0.0373407         0.262558   \n",
       "               1.000     0.508492          0.48684         0.520775   \n",
       "       100.000 0.001     0.878543        0.0441475         0.114419   \n",
       "               0.010     0.888776        0.0388304         0.122868   \n",
       "               0.100     0.907567        0.0406909         0.262558   \n",
       "               1.000     0.406325         0.476495          0.52093   \n",
       "       200.000 0.001     0.876144        0.0501855         0.122171   \n",
       "               0.010     0.886942        0.0429939         0.120155   \n",
       "               0.100     0.912648        0.0356647         0.272558   \n",
       "               1.000     0.469836         0.487189         0.522171   \n",
       "\n",
       "                     Tiempo ejecución  \n",
       "Kernel C       gamma                   \n",
       "linear 0.001   0.000          10.8988  \n",
       "       0.010   0.000          7.95344  \n",
       "       0.100   0.000          7.12892  \n",
       "       1.000   0.000          7.24083  \n",
       "       10.000  0.000          7.23485  \n",
       "       100.000 0.000          7.30681  \n",
       "       200.000 0.000          7.18888  \n",
       "rbf    0.001   0.001          10.2561  \n",
       "               0.010           10.415  \n",
       "               0.100          11.9292  \n",
       "               1.000          10.9597  \n",
       "       0.010   0.001          10.2022  \n",
       "               0.010          10.2131  \n",
       "               0.100          10.3361  \n",
       "               1.000           10.523  \n",
       "       0.100   0.001          10.0852  \n",
       "               0.010          10.2191  \n",
       "               0.100           10.421  \n",
       "               1.000          10.6459  \n",
       "       1.000   0.001          9.60549  \n",
       "               0.010          8.59407  \n",
       "               0.100          10.5699  \n",
       "               1.000          10.9337  \n",
       "       10.000  0.001          7.20986  \n",
       "               0.010          9.15675  \n",
       "               0.100           10.404  \n",
       "               1.000          11.1246  \n",
       "       100.000 0.001          7.45273  \n",
       "               0.010          9.07679  \n",
       "               0.100           10.474  \n",
       "               1.000          11.1876  \n",
       "       200.000 0.001          7.25084  \n",
       "               0.010          9.09078  \n",
       "               0.100           10.413  \n",
       "               1.000          11.1516  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0oI4Nx4KA1r"
   },
   "source": [
    "# Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJPjyvWTKA1t"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu9OMKpLKA1x"
   },
   "outputs": [],
   "source": [
    "def red_neuronal(nCO, nPC):\n",
    "    if(nCO==1):\n",
    "        mlp=MLPClassifier(activation='tanh',max_iter = 500,hidden_layer_sizes=(nPC))\n",
    "    else:\n",
    "        mlp=MLPClassifier(activation='tanh',max_iter = 500,hidden_layer_sizes=(nPC,nPC))\n",
    "        \n",
    "    acc = []\n",
    "    sens = []\n",
    "    esp = []\n",
    "    Errores = np.ones(100)\n",
    "    tiempo_i = time.time()\n",
    "    \n",
    "    j=0\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        Xtrain,Xtest,Ytrain,Ytest = train_test_split(bagOfWords,y)   #Realiza una única partición de la base de datos\n",
    "\n",
    "        mlp.fit(Xtrain,Ytrain)\n",
    "        Yest = mlp.predict(Xtest)\n",
    "        s, e = error_measures(Yest,Ytest)\n",
    "        sens.append(s); esp.append(e)\n",
    "        acc.append(mlp.score(Xtest,Ytest))\n",
    "        Errores[j] = classification_error(Yest, Ytest)\n",
    "        j+=1\n",
    "\n",
    "    return np.mean(acc), np.std(acc), np.mean(sens), np.std(sens), np.mean(esp), np.std(esp),np.mean(Errores), time.time()-tiempo_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csATbs1gKA10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 20\n",
      "1 24\n",
      "1 28\n",
      "1 32\n",
      "1 36\n",
      "2 20\n",
      "2 24\n",
      "2 28\n",
      "2 32\n",
      "2 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df7ae95071a42a8a5b27b21275802c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randn = np.random.randn\n",
    "\n",
    "df_types = pd.DataFrame({\n",
    "    'N. de capas ocultas' : pd.Series([1,1,1,1,1,2,2,2,2,2]),\n",
    "    'Neuronas por capa' : pd.Series([20,24,28,32,36,20,24,28,32,36])})\n",
    "\n",
    "df_types[\"Accuracy\"] = \"\"\n",
    "df_types[\"Int_Accuracy\"] = \"\"\n",
    "df_types[\"Sensibility\"] = \"\"\n",
    "df_types[\"Int_Sensibility\"] = \"\"\n",
    "df_types[\"Especificity\"] = \"\"\n",
    "df_types[\"Int_Especificity\"] = \"\"\n",
    "df_types[\"Error validación\"] = \"\"\n",
    "df_types[\"Tiempo ejecución\"] = \"\"\n",
    "df_types.set_index(['N. de capas ocultas','Neuronas por capa'], inplace=True)\n",
    "\n",
    "for i in df_types.index:\n",
    "    Acc, IntAcc, Sen, IntSen, Esp, IntEsp, error, tiempo=red_neuronal(i[0], i[1])       \n",
    "    print(i[0], i[1])\n",
    "    df_types[\"Accuracy\"][i] = Acc\n",
    "    df_types[\"Int_Accuracy\"][i] = IntAcc\n",
    "    df_types[\"Sensibility\"][i] = Sen\n",
    "    df_types[\"Int_Sensibility\"][i] = IntSen\n",
    "    df_types[\"Especificity\"][i] = Esp\n",
    "    df_types[\"Int_Especificity\"][i] = IntEsp\n",
    "    df_types[\"Error validación\"][i] = error\n",
    "    df_types[\"Tiempo ejecución\"][i] = tiempo\n",
    "        \n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXSfyIF9KA16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Int_Accuracy</th>\n",
       "      <th>Sensibility</th>\n",
       "      <th>Int_Sensibility</th>\n",
       "      <th>Especificity</th>\n",
       "      <th>Int_Especificity</th>\n",
       "      <th>Error validación</th>\n",
       "      <th>Tiempo ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N. de capas ocultas</th>\n",
       "      <th>Neuronas por capa</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>20</th>\n",
       "      <td>0.892326</td>\n",
       "      <td>0.0235357</td>\n",
       "      <td>0.924016</td>\n",
       "      <td>0.0319172</td>\n",
       "      <td>0.861255</td>\n",
       "      <td>0.0442534</td>\n",
       "      <td>0.107674</td>\n",
       "      <td>760.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.894574</td>\n",
       "      <td>0.0246604</td>\n",
       "      <td>0.923712</td>\n",
       "      <td>0.0340945</td>\n",
       "      <td>0.867072</td>\n",
       "      <td>0.0427562</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>772.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.927015</td>\n",
       "      <td>0.032485</td>\n",
       "      <td>0.864443</td>\n",
       "      <td>0.049903</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>839.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.0264476</td>\n",
       "      <td>0.924838</td>\n",
       "      <td>0.0320284</td>\n",
       "      <td>0.858225</td>\n",
       "      <td>0.0477324</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>971.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.894109</td>\n",
       "      <td>0.0243717</td>\n",
       "      <td>0.926542</td>\n",
       "      <td>0.0329527</td>\n",
       "      <td>0.863052</td>\n",
       "      <td>0.0447215</td>\n",
       "      <td>0.105891</td>\n",
       "      <td>1030.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>20</th>\n",
       "      <td>0.902403</td>\n",
       "      <td>0.0268332</td>\n",
       "      <td>0.925485</td>\n",
       "      <td>0.0371121</td>\n",
       "      <td>0.879929</td>\n",
       "      <td>0.0476317</td>\n",
       "      <td>0.0975969</td>\n",
       "      <td>501.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.903178</td>\n",
       "      <td>0.0235254</td>\n",
       "      <td>0.925731</td>\n",
       "      <td>0.032058</td>\n",
       "      <td>0.880733</td>\n",
       "      <td>0.0463686</td>\n",
       "      <td>0.0968217</td>\n",
       "      <td>538.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.903023</td>\n",
       "      <td>0.0240059</td>\n",
       "      <td>0.925914</td>\n",
       "      <td>0.0344023</td>\n",
       "      <td>0.880924</td>\n",
       "      <td>0.0410637</td>\n",
       "      <td>0.0969767</td>\n",
       "      <td>573.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.902171</td>\n",
       "      <td>0.0249458</td>\n",
       "      <td>0.915581</td>\n",
       "      <td>0.0350105</td>\n",
       "      <td>0.888567</td>\n",
       "      <td>0.0438096</td>\n",
       "      <td>0.0978295</td>\n",
       "      <td>611.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.908915</td>\n",
       "      <td>0.0256488</td>\n",
       "      <td>0.919194</td>\n",
       "      <td>0.0327905</td>\n",
       "      <td>0.899328</td>\n",
       "      <td>0.0411841</td>\n",
       "      <td>0.0910853</td>\n",
       "      <td>598.158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Accuracy Int_Accuracy Sensibility  \\\n",
       "N. de capas ocultas Neuronas por capa                                      \n",
       "1                   20                 0.892326    0.0235357    0.924016   \n",
       "                    24                 0.894574    0.0246604    0.923712   \n",
       "                    28                 0.895349     0.027176    0.927015   \n",
       "                    32                 0.891473    0.0264476    0.924838   \n",
       "                    36                 0.894109    0.0243717    0.926542   \n",
       "2                   20                 0.902403    0.0268332    0.925485   \n",
       "                    24                 0.903178    0.0235254    0.925731   \n",
       "                    28                 0.903023    0.0240059    0.925914   \n",
       "                    32                 0.902171    0.0249458    0.915581   \n",
       "                    36                 0.908915    0.0256488    0.919194   \n",
       "\n",
       "                                      Int_Sensibility Especificity  \\\n",
       "N. de capas ocultas Neuronas por capa                                \n",
       "1                   20                      0.0319172     0.861255   \n",
       "                    24                      0.0340945     0.867072   \n",
       "                    28                       0.032485     0.864443   \n",
       "                    32                      0.0320284     0.858225   \n",
       "                    36                      0.0329527     0.863052   \n",
       "2                   20                      0.0371121     0.879929   \n",
       "                    24                       0.032058     0.880733   \n",
       "                    28                      0.0344023     0.880924   \n",
       "                    32                      0.0350105     0.888567   \n",
       "                    36                      0.0327905     0.899328   \n",
       "\n",
       "                                      Int_Especificity Error validación  \\\n",
       "N. de capas ocultas Neuronas por capa                                     \n",
       "1                   20                       0.0442534         0.107674   \n",
       "                    24                       0.0427562         0.105426   \n",
       "                    28                        0.049903         0.104651   \n",
       "                    32                       0.0477324         0.108527   \n",
       "                    36                       0.0447215         0.105891   \n",
       "2                   20                       0.0476317        0.0975969   \n",
       "                    24                       0.0463686        0.0968217   \n",
       "                    28                       0.0410637        0.0969767   \n",
       "                    32                       0.0438096        0.0978295   \n",
       "                    36                       0.0411841        0.0910853   \n",
       "\n",
       "                                      Tiempo ejecución  \n",
       "N. de capas ocultas Neuronas por capa                   \n",
       "1                   20                         760.853  \n",
       "                    24                         772.201  \n",
       "                    28                         839.394  \n",
       "                    32                         971.446  \n",
       "                    36                          1030.9  \n",
       "2                   20                         501.831  \n",
       "                    24                         538.825  \n",
       "                    28                          573.21  \n",
       "                    32                         611.918  \n",
       "                    36                         598.158  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Implementacion de modelos2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
